{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "chEqqJbLzFew"
      },
      "source": [
        "# Yandex Data Science School\n",
        "## Linear Regression & Regularization Exercise.\n",
        "\n",
        "\n",
        "## Outline\n",
        "In this exercise you will learn the following topics:\n",
        "\n",
        "1. Refresher on how linear regression is solved in batch and in Gradient Descent \n",
        "2. Implementation of Ridge Regression\n",
        "3. Comparing Ridge, Lasso and vanila Linear Regression on a dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qW9qtzOS77sG"
      },
      "source": [
        "# Git Exercise\n",
        "In this exercise you will also experience working with github.\n",
        "\n",
        "You might need to install local python enviroment.\n",
        "Installation Instruction for ex2 - working on a local python environment:\n",
        "https://docs.google.com/document/d/1G0rBo36ff_9JzKy0EkCalK4m_ThNUuJ2bRz463EHK9I\n",
        "\n",
        "## please add the github link of your work below:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DCRBQ0_V77sK"
      },
      "source": [
        "example: https://github.com/username/exercise_name"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mR9UFmk2greT"
      },
      "source": [
        "## Refresher on Ordinary Least Square (OLS) aka Linear Regeression\n",
        "\n",
        "### Lecture Note\n",
        "\n",
        "In Matrix notation, the matrix $X$ is of dimensions $n \\times p$ where each row is an example and each column is a feature dimension. \n",
        "\n",
        "Similarily, $y$ is of dimension $n \\times 1$ and $w$ is of dimensions $p \\times 1$.\n",
        "\n",
        "The model is $\\hat{y}=X\\cdot w$ where we assume for simplicity that $X$'s first columns equals to 1 (one padding), to account for the bias term.\n",
        "\n",
        "Our objective is to optimize the loss $L$ defines as resiudal sum of squares (RSS): \n",
        "\n",
        "$L_{RSS}=\\frac{1}{N}\\left\\Vert Xw-y \\right\\Vert^2$ (notice that in matrix notation this means summing over all examples, so $L$ is scalar.)\n",
        "\n",
        "To find the optimal $w$ one needs to derive the loss with respect to $w$.\n",
        "\n",
        "$\\frac{\\partial{L_{RSS}}}{\\partial{w}}=\\frac{2}{N}X^T(Xw-y)$ (to see why, read about [matrix derivatives](http://www.gatsby.ucl.ac.uk/teaching/courses/sntn/sntn-2017/resources/Matrix_derivatives_cribsheet.pdf) or see class notes )\n",
        "\n",
        "Thus, the gardient descent solution is $w'=w-\\alpha \\frac{2}{N}X^T(Xw-y)$.\n",
        "\n",
        "Solving $\\frac{\\partial{L_{RSS}}}{\\partial{w}}=0$ for $w$ one can also get analytical solution:\n",
        "\n",
        "$w_{OLS}=(X^TX)^{-1}X^Ty$\n",
        "\n",
        "The first term, $(X^TX)^{-1}X^T$ is also called the pseudo inverse of $X$.\n",
        "\n",
        "See [lecture note from Stanford](https://web.stanford.edu/~mrosenfe/soc_meth_proj3/matrix_OLS_NYU_notes.pdf) for more details.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JA3MEKz80vdy"
      },
      "source": [
        "## Exercise 1 - Ordinary Least Square\n",
        "* Get the boston housing dataset by using the scikit-learn package. hint: [load_boston](http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_boston.html)\n",
        "\n",
        "* What is $p$? what is $n$ in the above notation? hint: [shape](https://docs.scipy.org/doc/numpy-1.15.0/reference/generated/numpy.ndarray.shape.html)\n",
        "\n",
        "* write a model `OrdinaryLinearRegression` which has a propoery $w$ and 3 methods: `fit`, `predict` and `score` (which returns the MSE on a given sample set). Hint: use [numpy.linalg.pinv](https://docs.scipy.org/doc/numpy-1.15.1/reference/generated/numpy.linalg.pinv.html) to be more efficient.\n",
        "\n",
        "* Fit the model. What is the training MSE?\n",
        "\n",
        "* Plot a scatter plot where on x-axis plot $Y$ and in the y-axis $\\hat{Y}_{OLS}$\n",
        "\n",
        "* Split the data to 75% train and 25% test 20 times. What is the average MSE now for train and test? Hint: use [train_test_split](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) or [ShuffleSplit](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.ShuffleSplit.html).\n",
        "\n",
        "* Use a t-test to proove that the MSE for training is significantly smaller than for testing. What is the p-value? Hint: use [scipy.stats.ttest_rel](https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.stats.ttest_rel.html). \n",
        "\n",
        "* Write a new class `OrdinaryLinearRegressionGradientDescent` which inherits from `OrdinaryLinearRegression` and solves the problem using gradinet descent. The class should get as a parameter the learning rate and number of iteration. Plot the class convergance. What is the effect of learning rate? How would you find number of iteration automatically? Note: Gradient Descent does not work well when features are not scaled evenly (why?!). Be sure to normalize your features first.\n",
        "\n",
        "* The following parameters are optional (not mandatory to use):\n",
        "    * early_stop - True / False boolean to indicate to stop running when loss stops decaying and False to continue.\n",
        "    * verbose- True/False boolean to turn on / off logging, e.g. print details like iteration number and loss (https://en.wikipedia.org/wiki/Verbose_mode)\n",
        "    * track_loss - True / False boolean when to save loss results to present later in learning curve graphs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "ZuSS8LhcfZdn"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "class Ols(object):\n",
        "    \"\"\" An implementation on ordinary least squares\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.w = None\n",
        "\n",
        "    @staticmethod\n",
        "    def pad(X):\n",
        "        X = np.c_[X, np.ones(X.shape[0])]\n",
        "        return X\n",
        "\n",
        "    def fit(self, X, Y):\n",
        "        # remeber pad with 1 before fitting\n",
        "        # Update the weight\n",
        "        X = Ols.pad(X)\n",
        "        self.w = self._derive(X, Y)\n",
        "\n",
        "    @staticmethod\n",
        "    def _derive(X, Y):\n",
        "        w_ols = np.dot(np.dot(np.linalg.pinv(np.dot(X.T, X)), X.T), Y)\n",
        "        return w_ols\n",
        "\n",
        "    def _fit(self, X, Y):\n",
        "        # optional to use this\n",
        "        pass\n",
        "\n",
        "    def predict(self, X):\n",
        "        # return wx\n",
        "        X = Ols.pad(X)\n",
        "        pred_y = np.dot(X, self.w)\n",
        "        return pred_y\n",
        "\n",
        "    def _predict(self, X):\n",
        "        # optional to use this\n",
        "        pass\n",
        "\n",
        "    def score(self, X, Y):\n",
        "        pred_y = self.predict(X)\n",
        "        mse = np.mean((pred_y - Y)**2)\n",
        "        return mse"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Getting the boston housing dataset by using the scikit-learn package."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(506, 13) (506,)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.datasets import load_boston\n",
        "\n",
        "X, y = load_boston(return_X_y=True)\n",
        "print(X.shape, y.shape)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Fitting the model. What is the training MSE?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MSE: 21.894831181729202\n"
          ]
        }
      ],
      "source": [
        "ols_obj = Ols()\n",
        "ols_obj.fit(X, y)\n",
        "mse = ols_obj.score(X, y)\n",
        "print('MSE:', mse)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plotting a scatter plot where on x-axis plot $Y$ and in the y-axis $\\hat{Y}_{OLS}$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.rc('font', size=16) # Enlarging font\n",
        "\n",
        "predicted_y = ols_obj.predict(X)\n",
        "\n",
        "plt.scatter(y, predicted_y)\n",
        "plt.xlabel('True Y')\n",
        "plt.ylabel('Predicted Y')\n",
        "\n",
        "plt.savefig('plots/true_vs_pred.png')  # Saving\n",
        "plt.show();\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Splitting the data to 75% train and 25% test 20 times.\n",
        "What is the average MSE now for train and test?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean MSE for train set: 21.13290214011827\n",
            "Mean MSE for test set: 25.811656089031306\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_mses = []\n",
        "test_mses = []\n",
        "for _ in range(20):\n",
        "    # Splitting the data\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
        "    # Defining the OLS object and fitting\n",
        "    curr_ols = Ols()\n",
        "    curr_ols.fit(X_train, y_train) \n",
        "    # Evaluating the MSE scores for the train and test sets\n",
        "    train_mses.append(curr_ols.score(X_train, y_train))\n",
        "    test_mses.append(curr_ols.score(X_test, y_test))\n",
        "\n",
        "print('Mean MSE for train set:', np.mean(train_mses))\n",
        "print('Mean MSE for test set:', np.mean(test_mses))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can see that the mean test MSE is larger than the mean train MSE."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "Rx0GRvGk77sV"
      },
      "outputs": [],
      "source": [
        "# Write a new class OlsGd which solves the problem using gradinet descent. \n",
        "# The class should get as a parameter the learning rate and number of iteration. \n",
        "# Plot the loss convergance. for each alpha, learning rate plot the MSE with respect to number of iterations.\n",
        "# What is the effect of learning rate? \n",
        "# How would you find number of iteration automatically? \n",
        "# Note: Gradient Descent does not work well when features are not scaled evenly (why?!). Be sure to normalize your feature first.\n",
        "class Normalizer():\n",
        "  def __init__(self, new_min = 0, new_max = 1):\n",
        "    self.new_min = new_min\n",
        "    self.new_max = new_max\n",
        "    # TODO: what to write?\n",
        "\n",
        "  def fit(self, X):\n",
        "    self.X = X  # TODO: Delet?\n",
        "    self.min = np.min(X)\n",
        "    self.max = np.max(X)\n",
        "\n",
        "  def predict(self, X):\n",
        "    norm_x = ((X - self.min)/(self.max - self.min)) * (self.new_max - self.new_min) + self.new_min\n",
        "    return norm_x\n",
        "\n",
        "class OlsGd(Ols):\n",
        "  \n",
        "  def __init__(self, learning_rate=.05, \n",
        "               num_iteration=1000, \n",
        "               normalize=True,\n",
        "               early_stop=True,\n",
        "               verbose=True):\n",
        "    \n",
        "    super(OlsGd, self).__init__()\n",
        "    self.learning_rate = learning_rate\n",
        "    self.num_iteration = num_iteration\n",
        "    self.early_stop = early_stop\n",
        "    self.normalize = normalize\n",
        "    self.normalizer = Normalizer()    \n",
        "    self.verbose = verbose\n",
        "    \n",
        "  def _fit(self, X, Y, reset=True, track_loss=True):\n",
        "    #remeber to normalize the data before starting\n",
        "    pass\n",
        "        \n",
        "  def _predict(self, X):\n",
        "    #remeber to normalize the data before starting\n",
        "    pass\n",
        "      \n",
        "  def _step(self, X, Y):\n",
        "    # use w update for gradient descent\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ 0  1  2  3  4  5  6  7  8  9 10]\n",
            "[0.  0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1. ]\n",
            "[1. 2. 3.]\n"
          ]
        }
      ],
      "source": [
        "############### TESTING NORMALIZAION ##############\n",
        "vec1 = np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
        "vec2 = np.array([1, 4, 9])\n",
        "\n",
        "norm = Normalizer()\n",
        "norm.fit(vec1)\n",
        "print(vec1)\n",
        "print(norm.predict(vec1))\n",
        "print(norm.predict([10, 20, 30]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7HVfnXvZFi98"
      },
      "source": [
        "## Exercise 2 - Ridge Linear Regression\n",
        "\n",
        "Recall that ridge regression is identical to OLS but with a L2 penalty over the weights:\n",
        "\n",
        "$L(y,\\hat{y})=\\sum_{i=1}^{i=N}{(y^{(i)}-\\hat{y}^{(i)})^2} + \\lambda \\left\\Vert w \\right\\Vert_2^2$\n",
        "\n",
        "where $y^{(i)}$ is the **true** value and $\\hat{y}^{(i)}$ is the **predicted** value of the $i_{th}$ example, and $N$ is the number of examples\n",
        "\n",
        "* Show, by differentiating the above loss, that the analytical solution is $w_{Ridge}=(X^TX+\\lambda I)^{-1}X^Ty$\n",
        "* Change `OrdinaryLinearRegression` and `OrdinaryLinearRegressionGradientDescent` classes to work also for ridge regression (do not use the random noise analogy but use the analytical derivation). Either add a parameter, or use inheritance.\n",
        "* **Bonus: Noise as a regularizer**: Show that OLS (ordinary least square), if one adds multiplicative noise to the features the **average** solution for $W$ is equivalent to Ridge regression. In other words, if $X'= X*G$ where $G$ is an uncorrelated noise with variance $\\sigma$ and mean 1, then solving for $X'$ with OLS is like solving Ridge for $X$. What is the interpretation? \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "JKrcabv777sY"
      },
      "outputs": [],
      "source": [
        "class RidgeLs(Ols):\n",
        "  def __init__(self, ridge_lambda, *wargs, **kwargs):\n",
        "    super(RidgeLs,self).__init__(*wargs, **kwargs)\n",
        "    self.ridge_lambda = ridge_lambda\n",
        "    \n",
        "  def _fit(self, X, Y):\n",
        "    #Closed form of ridge regression\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "voV47cV577se"
      },
      "source": [
        "### Use scikitlearn implementation for OLS, Ridge and Lasso"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KtdXmQ4T77sf"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "vscode": {
      "interpreter": {
        "hash": "d207591e6ff77a7c5fb4cef0dd9fd3703274637a9d0902d2045beb3a65bf572a"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
